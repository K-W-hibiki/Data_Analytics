{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PropensityScore:\r\n",
    "    def __init__(selef, df):\r\n",
    "        selef.df_data = df.copy()\r\n",
    "\r\n",
    "    def fit(self, X_vars, flag): #flag=treatment col_name\r\n",
    "        #calculate propensity score 'e' by Logistic Regression\r\n",
    "        self.model = LogisticRegression() \r\n",
    "        self.X = pd.get_dummies(self.df_data[X_vars]).values\r\n",
    "        self.y = self.df_data[flag].values\r\n",
    "        self.model.fit(self.X, self.y)\r\n",
    "        self.df_data[\"e\"] = self.model.predict_proba(self.X)[:, np.where(self.model.classes_ == 1)].flatten()\r\n",
    "\r\n",
    "    def estimate(self, flag, outcome): #flag & outcome =treatment & outcome col_name\r\n",
    "        #calculate 'IPWE'(Inverse Probability Weighting Estimator)\r\n",
    "        w1 = self.df_data[flag] / self.df_data[\"e\"]\r\n",
    "        w0 = (1 - self.df_data[flag]) / (1 - self.df_data[\"e\"]) \r\n",
    "        self.E1 = (np.sum(self.df_data[outcome] * w1)) / np.sum(w1) # E(y1)\r\n",
    "        self.E0 = (np.sum(self.df_data[outcome] * w0)) / np.sum(w0) # E(y0)\r\n",
    "\r\n",
    "        #calculate other expectation values\r\n",
    "        w1 = self.df_data[flag]\r\n",
    "        w0 = (1 - self.df_data[flag])\r\n",
    "        self.E11 = (np.sum(self.df_data[outcome] * w1)) / np.sum(w1) # E(y1|z=1)\r\n",
    "        self.E00 = (np.sum(self.df_data[outcome] * w0)) / np.sum(w0) # E(y0|z=0)\r\n",
    "        self.p1 = np.sum(w1) / np.sum(w0 + w1) # p(z=1)\r\n",
    "        self.p0 = np.sum(w0) / np.sum(w0 + w1) # p(z=0)\r\n",
    "\r\n",
    "        self.E10 = (self.E1 - self.E11 * self.p1) / self.p0 if self.p0 != 0 else None # E(y1|z=0)\r\n",
    "        self.E01 = (self.E0 - self.E00 * self.p0) / self.p1 if self.p1 != 0 else None # E(y0|z=1)\r\n",
    "\r\n",
    "        self.ATE = self.E1 - self.E0   # E(y1 - y0)\r\n",
    "        self.ATT = self.E11 - self.E01 # E(y1 - y0|z=1)\r\n",
    "        self.ATU = self.E10 - self.E00 # E(y1 - y0|z=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ps = PropensityScore(df)\r\n",
    "ps.fit([\"age\", \"gender\"], \"x_flag\")\r\n",
    "ps.estimate(\"x_flag\", \"x_rate\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('data-science': conda)"
  },
  "interpreter": {
   "hash": "7b5af0e2b86a111fb18c66074c1572458728c4e9862b8ed311611384e66ef3f0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}